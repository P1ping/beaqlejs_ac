{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install chardet -i https://mirrors.aliyun.com/pypi/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import IPython\n",
    "def play_audio(data, rate):\n",
    "    IPython.display.display(IPython.display.Audio(data=data,rate=rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000\n",
    "result_base_dir = \"./audio/20240815_spaccent/\"\n",
    "speakers = [\"BWC\", \"LXC\", \"NCC\", \"TXHC\"]\n",
    "\n",
    "experiments = {\n",
    "    \"mushra_naturalness\": [\n",
    "        \"source\",\n",
    "        \"resynth\",\n",
    "        \"pseudo\",\n",
    "        \"ours\",\n",
    "        \"ours-scale\",\n",
    "        \"ours-control-scale\",\n",
    "        \"baseline\",\n",
    "    ],\n",
    "    \"mushra_accentedness\": [\n",
    "        \"source\",\n",
    "        \"resynth\",\n",
    "        \"pseudo\",\n",
    "        \"ours\",\n",
    "        \"ours-scale\",\n",
    "        \"ours-control-scale\",\n",
    "        \"baseline\",\n",
    "    ],\n",
    "    \"bws_similarity\": [\n",
    "        \"source\", # reference\n",
    "        \"ours\", # Z\n",
    "        \"ours-scale\", # Y\n",
    "        \"ours-control-scale\", # X\n",
    "        \"baseline\", # W\n",
    "    ],\n",
    "    \"bws_naturalness\": [ # duration control\n",
    "        \"ours-scale\", # Z\n",
    "        \"ours-control-scale\", # Y\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "import chardet\n",
    "def openfile(txtfile):\n",
    "    with open(txtfile, \"rb\") as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "\n",
    "    with open(txtfile, \"r\", encoding=encoding) as f:\n",
    "        content = f.readlines()\n",
    "    return content\n",
    "files = glob.glob(\"../../seq2seq-vc/datasetgeneration/LLM_responses/08-A_multi-lingual_text/*.npy\")\n",
    "files.sort()\n",
    "groundtruth_dir = {}\n",
    "for file in files:\n",
    "    key = os.path.basename(file)[:-4]\n",
    "    text = np.load(file, allow_pickle=True).item()[\"Original English\"]\n",
    "    groundtruth_dir[key] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples_per_test = {\n",
    "    \"mushra_naturalness\": 15, # 15\n",
    "    \"mushra_accentedness\": 15, # 15\n",
    "    \"bws_similarity\": 15, # 15\n",
    "    \"bws_naturalness\": 15, # 15\n",
    "    # \"mushra_naturalness\": 3, # 15\n",
    "    # \"mushra_accentedness\": 3, # 15\n",
    "    # \"bws_similarity\": 5, # 15\n",
    "    # \"bws_naturalness\": 5, # 15\n",
    "}\n",
    "testnames = {\n",
    "    \"mushra_naturalness\": \"Speech Naturalness Evaluation (MUSHRA)\",\n",
    "    \"mushra_accentedness\": \"Speech Accentedness Evaluation (MUSHRA)\",\n",
    "    \"bws_similarity\": \"Speaker Similarity Evaluation (BWS)\", \n",
    "    \"bws_naturalness\": \"Speech Naturalness Evaluation (BWS)\", \n",
    "}\n",
    "testids = {\n",
    "    \"mushra_naturalness\": \"MUSHRANAT\",\n",
    "    \"mushra_accentedness\": \"MUSHRAACT\",\n",
    "    \"bws_similarity\": \"BWSSIM\", \n",
    "    \"bws_naturalness\": \"BWSNAT\", \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# MUSHRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "for exid in [\"mushra_naturalness\", \"mushra_accentedness\"]:\n",
    "# for exid in [\"mushra_accentedness\"]:\n",
    "# for exid in [\"mushra_naturalness\"]:\n",
    "    testname = testnames[exid]\n",
    "    testmode = exid.split(\"_\")[-1]\n",
    "    testid = testids[exid]\n",
    "    pngfile = \"img/scale_natural.png\" if testmode==\"naturalness\" else \"img/scale_accent.png\"\n",
    "    # pngfile = \"img/scale_abs.png\" if testmode==\"naturalness\" else \"img/scale_accent.png\"\n",
    "    def init():\n",
    "        whole_text = f\"\"\"var TestConfig = {{\n",
    "      \"TestName\": \"{testname}\",\n",
    "      \"RateScalePng\": \"{pngfile}\",\n",
    "      \"RateScaleBgPng\": \"img/scale_abs_background.png\",\n",
    "      \"RateMinValue\": 0,\n",
    "      \"RateMaxValue\": 100,\n",
    "      \"RateDefaultValue\":0,\n",
    "      \"ShowFileIDs\": false,\n",
    "      \"ShowResults\": false,\n",
    "      \"LoopByDefault\": false,\n",
    "      \"EnableABLoop\": true,\n",
    "      \"EnableOnlineSubmission\": false,\n",
    "      \"BeaqleServiceURL\": \"/web_service/beaqleJS_Service.php\",\n",
    "      \"SupervisorContact\": \"shoinoue@link.cuhk.edu.cn\",\n",
    "      \"RandomizeTestOrder\": true,\n",
    "      \"MaxTestsPerRun\": {nsamples_per_test[exid]},\n",
    "      \"RequireMaxRating\": false,\n",
    "      \"AudioRoot\": \"\",\n",
    "      \"Testsets\":\n",
    "    [\"\"\"\n",
    "        return whole_text\n",
    "\n",
    "    whole_text = init()\n",
    "    dirnames = experiments[exid]\n",
    "    dirname = dirnames[0]\n",
    "    for spk in speakers:\n",
    "        filenames = [os.path.basename(a)[:-4] for a in glob.glob(result_base_dir+f\"{dirname}_{spk}/*.wav\")]\n",
    "        filenames.sort()\n",
    "        for b, basename in enumerate(filenames):\n",
    "            _, name = basename.split(\"_\")\n",
    "            text = groundtruth_dir[basename]\n",
    "            starter = f\"\"\"\n",
    "      {{\n",
    "        \"Name\": \"{basename}\",\n",
    "        \"TestID\": \"{testid}---{basename}---{spk}\",\n",
    "        \"Text\": \"{text}\",\n",
    "        \"Files\": {{\\n\"\"\"\n",
    "            modelpaths = \"\"\"\"\"\"\n",
    "            for dirname in dirnames:\n",
    "                modelpath = result_base_dir+f\"{dirname}_{spk}/{basename}.wav\"\n",
    "                added = f'      \"{dirname}\": \"{modelpath}\",\\n'\n",
    "                modelpaths += added\n",
    "            ##### One more sample #####\n",
    "            np.random.seed(b)\n",
    "            dirname = dirnames[np.random.randint(len(dirnames))]\n",
    "            modelpath = result_base_dir+f\"{dirname}_{spk}/{basename}.wav\"\n",
    "            added = f'      \"{dirname}---2\": \"{modelpath}\",\\n'\n",
    "            modelpaths += added\n",
    "            ##########################\n",
    "            modelpaths += f'    }}\\n'\n",
    "            modelpaths += f'  }},'\n",
    "            whole_text += starter+modelpaths\n",
    "    whole_text += \"\\n]\\n}}\"\n",
    "    print(whole_text[:-1])\n",
    "    savefile = f\"./config/qibing_{exid}.js\"\n",
    "    try:\n",
    "        os.remove(savefile)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    if save:\n",
    "        f = open(savefile, \"a\")\n",
    "        f.write(whole_text[:-1])\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# BWS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = {\n",
    "    \"bws_similarity\":{\n",
    "        \"Low\": \"the 'LEAST' similar'\",\n",
    "        \"High\": \"the 'MOST' similar'\",\n",
    "    },\n",
    "    \"bws_naturalness\":{\n",
    "        \"Low\": \"the 'LEAST' natural'\",\n",
    "        \"High\": \"the 'MOST' natural'\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "bws_labels = [\"V\", \"W\", \"X\", \"Y\", \"Z\"][::-1]\n",
    "evaluation_filenames = [os.path.basename(a)[:-4] for a in glob.glob(\"./audio/20240815_spaccent/source_TXHC/*\")]\n",
    "evaluation_filenames.sort()\n",
    "for exid in [\"bws_similarity\", \"bws_naturalness\"]:\n",
    "# for exid in [\"bws_similarity\"]:\n",
    "    with_reference = exid in [\"bws_similarity\"]\n",
    "    testname = testnames[exid]\n",
    "    testmode = exid.split(\"_\")[-1]\n",
    "    testid = testids[exid]\n",
    "    instruction = instructions[exid]\n",
    "    def init():\n",
    "        whole_text = f\"\"\"var TestConfig = {{\n",
    "  \"TestName\": \"{testname}\",\n",
    "  \"LoopByDefault\": false,\n",
    "  \"ShowFileIDs\": false,\n",
    "  \"ShowResults\": false,\n",
    "  \"EnableABLoop\": true,\n",
    "  \"EnableOnlineSubmission\": false,\n",
    "  \"BeaqleServiceURL\": \"/web_service/beaqleJS_Service.php\",\n",
    "  \"MaxTestsPerRun\": {nsamples_per_test[exid]},\n",
    "  \"RandomizeTestOrder\": true,\n",
    "  \"SupervisorContact\": \"shoinoue@link.cuhk.edu.cn\",\n",
    "  \"AudioRoot\": \"\",\n",
    "  \"Testsets\":\n",
    "[\"\"\"\n",
    "        return whole_text\n",
    "\n",
    "    whole_text = init()\n",
    "    test_arrays = []\n",
    "    modelnames = experiments[exid]\n",
    "    lists = evaluation_filenames\n",
    "    for basename in lists:\n",
    "        for spk in speakers:\n",
    "            test_arrays += [[basename, spk]]\n",
    "    random.shuffle(test_arrays)\n",
    "    for test_array in test_arrays:\n",
    "        basename, spk = test_array\n",
    "        text = groundtruth_dir[basename]\n",
    "        if testmode==\"accentedness\":\n",
    "            text = f\"{text} --- Accent: {exid[0].upper()+exid[1:]}\"\n",
    "        starter = f\"\"\"\n",
    "  {{\n",
    "    \"Name\": \"{basename}\",\n",
    "    \"TestID\": \"{testid}---{basename}---{spk}\",\n",
    "    \"Text\": \"{text}\",\n",
    "    \"LowText\": \"{instruction['Low']}\",\n",
    "    \"HighText\": \"{instruction['High']}\",\n",
    "    \"Length\": {len(modelnames)-int(with_reference)},\n",
    "    \"Files\": {{\\n\"\"\"\n",
    "        modelpaths = \"\"\"\"\"\"\n",
    "        for d, dirname in enumerate(modelnames):\n",
    "            modelpath = result_base_dir+f\"{dirname}_{spk}/{basename}.wav\"\n",
    "            if with_reference and d==0:\n",
    "                label = \"Reference\"\n",
    "            else:\n",
    "                label = bws_labels[d-int(with_reference)]\n",
    "            added = f'      \"{label}\": \"{modelpath}\",\\n'\n",
    "            modelpaths += added\n",
    "        modelpaths += f'    }}\\n'\n",
    "        modelpaths += f'  }},'\n",
    "        whole_text += starter+modelpaths\n",
    "    whole_text += \"\\n]\\n}}\"\n",
    "    print(whole_text[:-1])\n",
    "    savefile = f\"./config/qibing_{exid}.js\"\n",
    "    try:\n",
    "        os.remove(savefile)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    if save:\n",
    "        f = open(savefile, \"a\")\n",
    "        f.write(whole_text[:-1])\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----\n",
    "----\n",
    "----\n",
    "----\n",
    "----\n",
    "----\n",
    "----\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 100000\n",
    "start = 0\n",
    "save = True\n",
    "with_reference = False\n",
    "evaluation_filenames = [\"arctic_a0024\", \"arctic_a0029\"]\n",
    "bws_labels = [\"W\", \"X\", \"Y\", \"Z\"][::-1]\n",
    "# for exid in [\"bws_similarity\", \"bws_naturalness\"]:\n",
    "for exid in [\"bws_similarity\"]:\n",
    "    testname = testnames[exid]\n",
    "    testmode = exid.split(\"_\")[-1]\n",
    "    testid = testids[exid]\n",
    "    def init():\n",
    "        whole_text = f\"\"\"var TestConfig = {{\n",
    "  \"TestName\": \"{testname}\",\n",
    "  \"LoopByDefault\": false,\n",
    "  \"ShowFileIDs\": false,\n",
    "  \"ShowResults\": false,\n",
    "  \"EnableABLoop\": true,\n",
    "  \"EnableOnlineSubmission\": false,\n",
    "  \"BeaqleServiceURL\": \"/web_service/beaqleJS_Service.php\",\n",
    "  \"SupervisorContact\": \"shoinoue@link.cuhk.edu.cn\",\n",
    "  \"AudioRoot\": \"\",\n",
    "  \"Testsets\":\n",
    "[\"\"\"\n",
    "        return whole_text\n",
    "\n",
    "    whole_text = init()\n",
    "    test_arrays = []\n",
    "    modelnames = experiments[exid]\n",
    "    for basename in evaluation_filenames:\n",
    "        for spk in speakers:\n",
    "            test_arrays += [[basename, spk]]\n",
    "    random.shuffle(test_arrays)\n",
    "    for test_array in test_arrays:\n",
    "        basename, spk = test_array\n",
    "        text = groundtruth_dir[basename]\n",
    "        if testmode==\"accentedness\":\n",
    "            text = f\"{text} --- Accent: {exid[0].upper()+exid[1:]}\"\n",
    "        starter = f\"\"\"\n",
    "  {{\n",
    "    \"Name\": \"{basename}\",\n",
    "    \"TestID\": \"{testid}---{basename}---{spk}\",\n",
    "    \"Text\": \"{text}\",\n",
    "    \"Length\": {len(modelnames)-int(with_reference)},\\n\"\"\"\n",
    "        if with_reference:\n",
    "            dirname = modelnames[0]\n",
    "            modelpath = result_base_dir+f\"{dirname}___{spk}/{basename}.wav\"\n",
    "            starter += f\"\"\"\n",
    "    \"Reference\": \"{modelpath}\",\n",
    "    \"Files\": {{\\n\"\"\"[1:]\n",
    "        else:\n",
    "            starter += f\"\"\"\n",
    "    \"Files\": {{\\n\"\"\"[1:]\n",
    "        modelpaths = \"\"\"\"\"\"\n",
    "        for d, dirname in enumerate(modelnames[int(with_reference):]):\n",
    "            modelpath = result_base_dir+f\"{dirname}___{spk}/{basename}.wav\"\n",
    "            added = f'      \"{bws_labels[d]}\": \"{modelpath}\",\\n'\n",
    "            modelpaths += added\n",
    "        modelpaths += f'    }}\\n'\n",
    "        modelpaths += f'  }},'\n",
    "        whole_text += starter+modelpaths\n",
    "    whole_text += \"\\n]\\n}}\"\n",
    "    print(whole_text[:-1])\n",
    "    savefile = f\"./config/qibing_{exid}.js\"\n",
    "    try:\n",
    "        os.remove(savefile)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    if save:\n",
    "        f = open(savefile, \"a\")\n",
    "        f.write(whole_text[:-1])\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 100000\n",
    "start = 0\n",
    "save = True\n",
    "evaluation_filenames = [\"arctic_a0024\", \"arctic_a0029\"]\n",
    "bws_labels = [\"W\", \"X\", \"Y\", \"Z\"][::-1]\n",
    "# for exid in [\"bws_similarity\", \"bws_naturalness\"]:\n",
    "for exid in [\"bws_similarity\"]:\n",
    "    testname = testnames[exid]\n",
    "    testmode = exid.split(\"_\")[-1]\n",
    "    testid = testids[exid]\n",
    "    def init():\n",
    "        whole_text = f\"\"\"var TestConfig = {{\n",
    "  \"TestName\": \"{testname}\",\n",
    "  \"LoopByDefault\": false,\n",
    "  \"ShowFileIDs\": false,\n",
    "  \"ShowResults\": false,\n",
    "  \"EnableABLoop\": true,\n",
    "  \"EnableOnlineSubmission\": false,\n",
    "  \"BeaqleServiceURL\": \"/web_service/beaqleJS_Service.php\",\n",
    "  \"SupervisorContact\": \"shoinoue@link.cuhk.edu.cn\",\n",
    "  \"AudioRoot\": \"\",\n",
    "  \"Testsets\":\n",
    "[\"\"\"\n",
    "        return whole_text\n",
    "\n",
    "    whole_text = init()\n",
    "    test_arrays = []\n",
    "    modelnames = experiments[exid]\n",
    "    for basename in evaluation_filenames:\n",
    "        for spk in speakers:\n",
    "            test_arrays += [[basename, spk]]\n",
    "    random.shuffle(test_arrays)\n",
    "    for test_array in test_arrays:\n",
    "        basename, spk = test_array\n",
    "        text = groundtruth_dir[basename]\n",
    "        if testmode==\"accentedness\":\n",
    "            text = f\"{text} --- Accent: {exid[0].upper()+exid[1:]}\"\n",
    "        starter = f\"\"\"\n",
    "  {{\n",
    "    \"Name\": \"{basename}\",\n",
    "    \"TestID\": \"{testid}---{basename}---{spk}\",\n",
    "    \"Text\": \"{text}\",\n",
    "    \"Length\": {len(modelnames)},\n",
    "    \"Files\": {{\\n\"\"\"\n",
    "        modelpaths = \"\"\"\"\"\"\n",
    "        for d, dirname in enumerate(modelnames):\n",
    "            dirname = f'{\"___\".join(dirname.split(\"/\"))}'\n",
    "            modelpath = result_base_dir+f\"{dirname}___{spk}/{basename}.wav\"\n",
    "            added = f'      \"{bws_labels[d]}\": \"{modelpath}\",\\n'\n",
    "            modelpaths += added\n",
    "        modelpaths += f'    }}\\n'\n",
    "        modelpaths += f'  }},'\n",
    "        whole_text += starter+modelpaths\n",
    "    whole_text += \"\\n]\\n}}\"\n",
    "    print(whole_text[:-1])\n",
    "    savefile = f\"./config/qibing_{exid}.js\"\n",
    "    try:\n",
    "        os.remove(savefile)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    if save:\n",
    "        f = open(savefile, \"a\")\n",
    "        f.write(whole_text[:-1])\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "emos = [\"Angry\", \"Happy\", \"Sad\", \"Surprise\"]\n",
    "\n",
    "def init():\n",
    "    whole_text = \"\"\"var TestConfig = {\n",
    "  \"TestName\": \"Utterance-level Emotion Intensity Evaluation\",\n",
    "  \"LoopByDefault\": false,\n",
    "  \"ShowFileIDs\": false,\n",
    "  \"ShowResults\": false,\n",
    "  \"EnableABLoop\": true,\n",
    "  \"EnableOnlineSubmission\": true,\n",
    "  \"BeaqleServiceURL\": \"/web_service/beaqleJS_Service.php\",\n",
    "  \"SupervisorContact\": \"shoinoue@link.cuhk.edu.cn\",\n",
    "  \"AudioRoot\": \"\",\n",
    "  \"Testsets\":\n",
    "[\\n\"\"\"\n",
    "    return whole_text\n",
    "\n",
    "evaluation_filenames = [\n",
    "    # \"0013_000731\",\n",
    "    \"0014_000732\",\n",
    "    \"0015_000726\",\n",
    "    # \"0018_000037\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 10000000\n",
    "start = 0\n",
    "whole_text = init()\n",
    "result_dir = result_base_dir + f\"utterance_remain/\"\n",
    "intensities = [\"0.0\", \"0.6\", \"1.0\"]\n",
    "intensity_label = [\"L\", \"M\", \"H\"]\n",
    "modelnames = list(set(experiments[\"main\"]+ experiments[\"methods\"] + experiments[\"features\"]))\n",
    "modelnames.sort()\n",
    "filenames = glob.glob(f\"{result_dir}{modelnames[0]}/*-Angry-0.0-0.wav\")\n",
    "filenames.sort()\n",
    "for path in filenames[start:start+num]:\n",
    "    basename = os.path.basename(path).split(\".\")[0]\n",
    "    basename, _, _ = basename.split(\"-\")\n",
    "    if not (basename in evaluation_filenames):\n",
    "        continue\n",
    "    spk, name = basename.split(\"_\")\n",
    "    for emotion in emos:\n",
    "        for mn in modelnames:\n",
    "            if \"msemotts\" in mn:\n",
    "                continue\n",
    "            starter = \"  {\\n\"\n",
    "            starter += f'    \"Name\": \"{basename}-{emotion}\",\\n'\n",
    "            starter += f'    \"TestID\": \"{mn}---{basename}---{emotion}\",\\n'\n",
    "            starter += f'    \"Text\": \"Intended Emotion: <b>{emotion}</b>\",\\n'\n",
    "            starter += f'    \"Files\": {{\\n'\n",
    "            modelpaths = \"\"\"\"\"\"\n",
    "            for itt, intensity in enumerate(intensities):\n",
    "                modelpath = result_dir + f\"{mn}/{basename}-{emotion}-{intensity}-0.wav\"\n",
    "                added = f'      \"{intensity_label[itt]}\": \"{modelpath}\",\\n'\n",
    "                modelpaths += added\n",
    "            modelpaths += f'    }}\\n'\n",
    "            modelpaths += f'  }},\\n'\n",
    "            whole_text += starter+modelpaths\n",
    "whole_text += \"]\\n}}\"\n",
    "print(whole_text[:-1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15",
   "metadata": {},
   "source": [
    "save_dir = \"/Users/shoahoshoaho/Downloads/samples/\"\n",
    "exid = \"hindi\"\n",
    "num = 20\n",
    "\n",
    "dirnames = experiments[exid]\n",
    "dirname = dirnames[0]\n",
    "dirname = f'{\"___\".join(dirname.split(\"/\"))}'\n",
    "filenames = [os.path.basename(a)[:-4] for a in glob.glob(result_base_dir+f\"{dirname}/*.wav\")]\n",
    "filenames.sort()\n",
    "np.random.seed(42)\n",
    "bl = np.random.choice(np.arange(len(filenames)), size=num, replace=False)\n",
    "for b, basename in enumerate(np.array(filenames)[bl]):\n",
    "    print(basename)\n",
    "    spk, name = basename.split(\"_\")\n",
    "    gt_path = result_base_dir + f\"ground_truth/{basename}.wav\"\n",
    "    for d, dirname in enumerate(dirnames):\n",
    "        print(dirname)\n",
    "        savepath = save_dir + f\"{b}_{d}.wav\"\n",
    "        dirname = f'{\"___\".join(dirname.split(\"/\"))}'\n",
    "        modelpath = result_base_dir+f\"{dirname}/{basename}.wav\"\n",
    "        play_audio(modelpath, 16000)\n",
    "        shutil.copy(modelpath, savepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
