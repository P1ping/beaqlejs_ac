{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy.stats as st\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/shoahoshoaho/Git/cuhksz-phd/sho_util/pyfiles/\")\n",
    "from basic import get_bool_base_on_conditions\n",
    "\n",
    "def get_json(path):\n",
    "    with open(path, 'r') as j:\n",
    "         contents = json.loads(j.read())\n",
    "    return contents\n",
    "\n",
    "sr = 16000\n",
    "result_base_dir = \"./audio/20240815_spaccent/\"\n",
    "\n",
    "experiments = {\n",
    "    \"hindi\": [\n",
    "        \"CMU-ARCTIC/SLT\",\n",
    "        \"PD-AST/SLT/English\",\n",
    "        \"L2-ARCTIC/ASI\",\n",
    "        \"L2-ARCTIC/TNI\",\n",
    "        \"PD-AST/SLT/Hindi\",\n",
    "        \"PD-AST/ASI/Hindi\",\n",
    "        \"PD-AST/TNI/Hindi\",\n",
    "        \"VTN_fine-tuning_nocondition_gt2syn_hifiganmelhifiganmel_hubert_norepeating/100000\",\n",
    "        \"VTN_fine-tuning_nocondition_mix2synVCTK3hr_hifiganmelhifiganmel_hubert_norepeating/100000\",\n",
    "    ],\n",
    "    \"korean\": [\n",
    "        \"CMU-ARCTIC/SLT\",\n",
    "        \"PD-AST/SLT/English\",\n",
    "        \"L2-ARCTIC/HKK\",\n",
    "        \"L2-ARCTIC/YDCK\",\n",
    "        \"PD-AST/SLT/Korean\",\n",
    "        \"PD-AST/HKK/Korean\",\n",
    "        \"PD-AST/YDCK/Korean\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_control_result(contents, name, sampleid, segment):\n",
    "    arrays = []\n",
    "    for idx, a in enumerate(contents):\n",
    "        if idx>=48:\n",
    "            continue\n",
    "        mn, fileid, emotion = a[\"TestID\"].split(\"---\")[-3:]\n",
    "        allocation = {item[0]: item[2] for item in a[\"PresentationOrder\"].split(\", \")}\n",
    "        res = [allocation[key] for key in a[\"Preference\"]]\n",
    "        array = [mn, fileid, emotion, *res]\n",
    "        arrays += [array]\n",
    "\n",
    "    columns = [\"model name\", \"file id\", \"emotion\", \"Lowest Prediction\", \"Highest Prediction\"]\n",
    "    sampledf = pd.DataFrame(np.array(arrays), columns=columns)\n",
    "    samplearrays = []\n",
    "    for mn in modelnames:\n",
    "        for fileid in sampledf[\"file id\"].unique():\n",
    "            params = {\"model name\": [mn], \"file id\": [fileid]}\n",
    "            modeldf = sampledf[get_bool_base_on_conditions(sampledf, params)]\n",
    "            if len(modeldf)>0:\n",
    "                int_array = []\n",
    "                for emotion in emos:\n",
    "                    params = {\"emotion\": [emotion]}\n",
    "                    emotiondf = modeldf[get_bool_base_on_conditions(modeldf, params)]\n",
    "                    a = [(emotiondf[\"Lowest Prediction\"]==label).sum() for label in intensitylabels]\n",
    "                    b = [(emotiondf[\"Highest Prediction\"]==label).sum() for label in intensitylabels]\n",
    "                    int_array += [a + b]\n",
    "                array = list(np.array(int_array).reshape(-1)) + list(np.sum(np.array(int_array), axis=0))\n",
    "            else:\n",
    "                array = [None]*30\n",
    "            samplearrays += [[name, sampleid, fileid, mn, *array]]\n",
    "\n",
    "    columns = []\n",
    "    for cl in [\"Test Name\", \"Test ID\", \"File ID\", \"model name\"]:\n",
    "        columns += [(\"basic\", \"\", cl)]\n",
    "    for emotion in emos + [\"total\"]:\n",
    "        for key in [\"LP\", \"HP\"]:\n",
    "            for label in intensitylabels:\n",
    "                columns += [(f\"{segment}-level control\", emotion, f\"{key}-{label}\")]\n",
    "    result = pd.DataFrame(np.array(samplearrays), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    return result\n",
    "\n",
    "def get_mushra_result(contents, name, sampleid, metric):\n",
    "    arrays = []\n",
    "    for idx, a in enumerate(contents):\n",
    "        if idx>=100:\n",
    "            continue\n",
    "        if len(a)==1:\n",
    "            continue\n",
    "        _, fileid = a[\"TestID\"].split(\"---\")\n",
    "        ratings = a[\"rating\"]\n",
    "        arrays += [[name, sampleid, fileid, key, ratings[key]]for key in ratings]\n",
    "    columns = []\n",
    "    for cl in [\"Test Name\", \"Test ID\", \"File ID\", \"model name\"]:\n",
    "        columns += [(\"basic\",  cl)]\n",
    "    for label in [f\"{metric}\"]:\n",
    "        columns += [(metric, \"score\")]\n",
    "    result = pd.DataFrame(np.array(arrays), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    result.loc[:, [metric]] = result.loc[:, [metric]].values.astype(float)\n",
    "    return result\n",
    "\n",
    "def get_contents(path):\n",
    "    contents = get_json(path)\n",
    "    name = contents[-1][\"UserName\"]\n",
    "    sampleid = path[:-5].split(\"_\")[-1]\n",
    "    return contents, name, sampleid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contents(path):\n",
    "    contents = get_json(path)\n",
    "    name = contents[-1][\"UserName\"]\n",
    "    sampleid = path[:-5].split(\"_\")[-1]\n",
    "    return contents, name, sampleid\n",
    "\n",
    "def get_mushra_result(contents, name, sampleid, metric):\n",
    "    arrays = []\n",
    "    for idx, a in enumerate(contents):\n",
    "        if idx>=100:\n",
    "            continue\n",
    "        if len(a)==1:\n",
    "            continue\n",
    "        _, fileid = a[\"TestID\"].split(\"---\")\n",
    "        ratings = a[\"rating\"]\n",
    "        arrays += [[name, sampleid, fileid, key, ratings[key]]for key in ratings]\n",
    "    columns = []\n",
    "    for cl in [\"Test Name\", \"Test ID\", \"File ID\", \"model name\"]:\n",
    "        columns += [(\"basic\",  cl)]\n",
    "    for label in [f\"{metric}\"]:\n",
    "        columns += [(metric, \"score\")]\n",
    "    result = pd.DataFrame(np.array(arrays), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    result.loc[:, [metric]] = result.loc[:, [metric]].values.astype(float)\n",
    "    return result\n",
    "\n",
    "def get_diffs(result):\n",
    "    diffs = []\n",
    "    params = {(\"basic\", \"model name\"): [a for a in list(set(list(result[(\"basic\", \"model name\")].unique())) - set(excluded_list)) if \"---2\" in a]}\n",
    "    df = result[get_bool_base_on_conditions(result, params, True)]\n",
    "    for array in df.values:\n",
    "        _, _, fileid, mn, _ = array\n",
    "        mn2 = mn.split(\"---\")[0]\n",
    "        params = {(\"basic\", \"File ID\"): [fileid], (\"basic\", \"model name\"):[mn, mn2]}\n",
    "        result[get_bool_base_on_conditions(result, params, True)]\n",
    "        scores = result[get_bool_base_on_conditions(result, params, True)].values[:, -1]\n",
    "        diffs += [np.abs(scores[0]-scores[1])]\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultfiles = glob.glob(f\"./web_service/results/*.json\")\n",
    "resultfiles.sort()\n",
    "\n",
    "not_found = []\n",
    "results = {key: [] for key in [\"NATHindi\", \"ACTHindi\", \"NATKorean\", \"ACTKorean\"]}\n",
    "filenames = {key: [] for key in [\"NATHindi\", \"ACTHindi\", \"NATKorean\", \"ACTKorean\"]}\n",
    "for path in resultfiles:\n",
    "    contents, name, sampleid = get_contents(path)\n",
    "    testtype = contents[0][\"TestID\"].split(\"---\")[0]\n",
    "    if testtype==\"NATHindi\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    elif testtype==\"ACTHindi\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    if testtype==\"NATKorean\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    elif testtype==\"ACTKorean\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    diffs = get_diffs(result)\n",
    "    fn = os.path.basename(path).split(\".\")[0]\n",
    "    print(fn, name, testtype, np.mean(diffs))\n",
    "    result[(\"basic\", \"model name\")] = [a.split(\"---\")[0] for a in result[(\"basic\", \"model name\")].values]\n",
    "    results[testtype] += [result]\n",
    "    filenames[testtype] += [fn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Check Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [\n",
    "    \"20240902-0739_Reichan_22943887\" # Only check the noise\n",
    "    \"Hindi-1-124457_\", # Too unreliable (different scores for the same audio samples)\n",
    "    \"Hindi-5-093328_\", # Random selection \n",
    "    \"Hindi-5-120547_\", # Random selection\n",
    "    \"Korean-3-124457_\", # Retaken\n",
    "    \"Korean-3-130728_\", # Retaken\n",
    "    \"Korean-4-101351_\", # Only check the noise\n",
    "    \"Korean-5-093609_\", # Random selection\n",
    "    \"Korean-5-122039_\", # Random selection\n",
    "    \"Korean-5-add-182021_\", # Only check the noise (too low for the ground-truth)\n",
    "    \"test\",\n",
    "]\n",
    "for metric in results:\n",
    "    alive = [a for a in filenames[metric] if not(a in errors)]\n",
    "    print(metric, len(alive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "metric = \"NATKorean\"\n",
    "\n",
    "result = results[metric][idx]\n",
    "fn = filenames[metric][idx]\n",
    "print(fn)\n",
    "print(result[(\"basic\", \"Test Name\")][0])\n",
    "result.groupby([(\"basic\",\"Test Name\"), (\"basic\",\"model name\")]).mean()[metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_gradient(val, min_val=-1, max_val=1, color='red'):\n",
    "    if val < min_val: val = min_val\n",
    "    if val > max_val: val = max_val\n",
    "    normalized_val = (val - min_val) / (max_val - min_val)\n",
    "    \n",
    "    if color == 'red':\n",
    "        red_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb({red_intensity}, 0, 0)'\n",
    "    elif color == 'green':\n",
    "        green_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb(0, {green_intensity}, 0)'\n",
    "    elif color == 'blue':\n",
    "        blue_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb(0, 0, {blue_intensity})'\n",
    "    else:\n",
    "        return 'background-color: none'\n",
    "\n",
    "def apply_color_gradient(df, min_val=0, max_val=1.0):\n",
    "    \"\"\"\n",
    "    df.style.apply(lambda x:apply_color_gradient(x, min_val=0, max_val=100), axis=None)\n",
    "    \"\"\"\n",
    "    styles = df.copy()\n",
    "    for col in styles.columns:\n",
    "        color = 'red' if \"LP\" in col else \"green\"\n",
    "        color = \"blue\" if col==\"mean\" else color\n",
    "        styles[col] = df[col].apply(color_gradient, min_val=min_val, max_val=max_val, color=color)\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "- MUSHRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization = False\n",
    "excluded_list = []\n",
    "\n",
    "dfdir = {}\n",
    "for metric in [\"NATHindi\", \"ACTHindi\", \"NATKorean\", \"ACTKorean\"]:\n",
    "    add = [\"ground_truth\", \"reconstruct\"] if metric==\"NAT\" else []\n",
    "    accent = metric[3:].lower()\n",
    "    \n",
    "    models = experiments[accent]\n",
    "    models = [\"___\".join(mn.split(\"/\")) for mn in models]\n",
    "    \n",
    "    idxlist = [a for a in range(len(filenames[metric])) if not(filenames[metric][a] in errors)]\n",
    "    df_list = []\n",
    "    df = pd.concat([results[metric][idx] for idx in idxlist], axis=0)\n",
    "    params = {(\"basic\", \"Test Name\"): list(set(list(df[(\"basic\", \"Test Name\")].unique())) - set(excluded_list))}\n",
    "    df = df[get_bool_base_on_conditions(df, params, True)]\n",
    "    if standardization:\n",
    "        for testid in df[(\"basic\", \"Test ID\")].unique():\n",
    "            a = df[get_bool_base_on_conditions(df, {(\"basic\", \"Test ID\"): [testid]}, True)]\n",
    "            col = (metric, \"score\")\n",
    "            df.loc[get_bool_base_on_conditions(df, {(\"basic\", \"Test ID\"): [testid]}, True), col]  = (a[col] - a[col].mean()) / a[col].std() \n",
    "    arrays = []\n",
    "    for mn in add+models:\n",
    "        params = {(\"basic\", \"model name\"): [mn]}\n",
    "        d = df[get_bool_base_on_conditions(df, params, True)]\n",
    "        values = d[(metric, \"score\")].values\n",
    "        mean = np.mean(values)\n",
    "        # ivl = st.t.interval(alpha=0.95, df=len(values)-1, loc=np.mean(values), scale=st.sem(values)) \n",
    "        ivl = st.t.interval(confidence=0.95, df=len(values)-1, loc=np.mean(values), scale=st.sem(values)) \n",
    "        ivl = (ivl[1]-ivl[0])/2\n",
    "        arrays += [[mean, ivl]]\n",
    "    df = pd.DataFrame(arrays, index=add+models, columns=[\"mean\", \"interval\"])\n",
    "    dfdir[metric] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"NATHindi\"\n",
    "df = dfdir[mode]\n",
    "df.style.apply(lambda x:apply_color_gradient(x, min_val=df[\"mean\"].min(), max_val=df[\"mean\"].max()), axis=None, subset=[\"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in dfdir:\n",
    "    savefile = f\"summary/{mode}.csv\"\n",
    "    df = dfdir[mode]\n",
    "    df.to_csv(savefile)\n",
    "    d = pd.read_csv(savefile, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
